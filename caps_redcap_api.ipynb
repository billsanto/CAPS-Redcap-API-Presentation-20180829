{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with Redcap and the Redcap API\n",
    "- Intro to Pandas library\n",
    "- Intro to Redcapy library\n",
    "- Intro to Twilio API\n",
    "\n",
    "- The beginning is a highly abbreviated version of what is available here: https://pandas.pydata.org/pandas-docs/stable/10min.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries\n",
    "- pd and np are standard conventions\n",
    "- Pandas is the standard library for working with data\n",
    " - Ref: https://pandas.pydata.org/pandas-docs/stable/index.html\n",
    " - Book: https://www.amazon.com/Python-Data-Analysis-Wrangling-IPython/dp/1491957662/\n",
    " - Free to read on the UCSF network: http://proquest.safaribooksonline.com/book/programming/python/9781491957653/firstchapter\n",
    "- Numpy is the standard library for array processing and scientific computing\n",
    " - Ref: http://www.numpy.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.debugger import set_trace  # for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A series is a basic Pandas data structure\n",
    "- Element types are floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 3, 5, np.nan, 6, 8])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series type is Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(s)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A DataFrame is comprised of series and an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('20130101', periods=6)\n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DataFrame with random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data type of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the beginning or end of data with head or tail\n",
    "- default is up to 5 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)  # first three rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last row with tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract a column of a DataFrame using an attribute\n",
    "- Returns a Series\n",
    "- Existing DataFrame column names are available with TAB completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or extract using bracket notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brackets are useful when using a variable for the column name\n",
    "- Note: Bracket notation is required when creating a new DataFrame column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_col = 'A'\n",
    "df[my_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract multiple columns by passing a list to the brackets\n",
    "- Returns a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['A', 'B']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the index from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index  # or convert to a list by: list(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, create a new DataFrame with different series types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({ 'A' : 1.,\n",
    "                    'B' : pd.Timestamp('20130102'),\n",
    "                    'C' : pd.Series(1, index=list(range(4)), dtype='float32'),\n",
    "                    'D' : np.array([3] * 4, dtype='int32'),\n",
    "                    'E' : pd.Categorical([\"test\",\"train\",\"test\",\"train\"]),\n",
    "                    'F' : 'foo' })\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Column Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply an operation to a column of the DataFrame\n",
    "- Double each element of column D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.D * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.F + 'bar'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add columns C and D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.C + df2.D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply an operation to a column, contingent on a value in another column\n",
    "- Use .apply()\n",
    "- Use axis=1 to operate over each row of the DataFrame\n",
    "- All but the most simple operations will involve a lambda expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['D2'] = df2.apply(lambda row: row.D * 2 if row.E == 'test' else row.D, axis=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply an operation to a Series, not contingent on a value in another column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['D3'] = df2.D2.apply(lambda x: x * 3 if x == df2.D2.min() else x)\n",
    "df2['D3'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pre-randomization data that resembles a JSON export from Redcap\n",
    "- Every record always contains\n",
    " - record_id\n",
    " - redcap_event_name\n",
    "- Data from a repeating instrument will also contain\n",
    " - redcap_repeat_instrument\n",
    " - redcap_repeat_instance\n",
    " \n",
    " \n",
    "- Data is intuitively stacked by record id and event and repeating instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_import = [\n",
    "    {'record_id': '1',\n",
    "     'redcap_event_name': 'baseline_arm_1',\n",
    "     'part_first_name': 'Ann',\n",
    "     'part_last_name': 'Apple',\n",
    "     'part_age': '3',\n",
    "     'part_mobile_number': '415-555-1212',\n",
    "    },\n",
    "    {'record_id': '2',\n",
    "     'redcap_event_name': 'baseline_arm_1',\n",
    "     'part_first_name': 'Bob',\n",
    "     'part_last_name': 'Barley',\n",
    "     'part_age': '4',\n",
    "     'part_mobile_number': '415-555-1212',\n",
    "    },\n",
    "    {'record_id': '4',\n",
    "     'redcap_event_name': 'baseline_arm_1',\n",
    "     'part_first_name': 'Don',\n",
    "     'part_last_name': 'Dill',\n",
    "     'part_age': '6',\n",
    "     'part_mobile_number': '415-555-1212',\n",
    "    },\n",
    "    {'record_id': '5',\n",
    "     'redcap_event_name': 'baseline_arm_1',\n",
    "     'part_first_name': 'Eve',\n",
    "     'part_last_name': 'Eggs',\n",
    "     'part_age': '5',\n",
    "     'part_mobile_number': '415-555-1212',\n",
    "    },    \n",
    "]\n",
    "\n",
    "rci_df = pd.DataFrame(rc_import)\n",
    "rci_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Redcapy instances for importing and exporting\n",
    "- In this example, the same tokens are used for both instances, but using different tokens can be useful for:\n",
    " - Merging data from multiple projects\n",
    " - Testing imports by exporting from production project and importing into a development copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redcap.redcapy import Redcapy\n",
    "import os\n",
    "\n",
    "redcap_token = os.environ['REDCAP_API_CAPS_DEMO']\n",
    "redcap_url = os.environ['REDCAP_URL']\n",
    "\n",
    "rce = Redcapy(api_token=redcap_token, redcap_url=redcap_url)\n",
    "rci = Redcapy(api_token=redcap_token, redcap_url=redcap_url)\n",
    "\n",
    "data_to_import = rci_df.to_json(orient='records')\n",
    "data_to_import, type(data_to_import)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a simple function to import records into Redcap\n",
    "- The Redcapy import_records function imports data one record at a time, and does not perform a bulk import of multiple records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_to_redcap(redcap_instance, df_to_upload):\n",
    "    import_success_count = 0\n",
    "    import_attempt_count = 0\n",
    "    \n",
    "    for i, row in df_to_upload.iterrows():\n",
    "        record_to_upload = row.to_json(orient='columns')\n",
    "#         print(record_to_upload)\n",
    "        import_return = redcap_instance.import_records(data_to_upload=record_to_upload)  # returns {'count': 1} if successful\n",
    "        \n",
    "        import_success_count += 1 if 'count' in import_return and import_return['count'] == 1 else 0\n",
    "        import_attempt_count += 1\n",
    "        \n",
    "    return import_success_count, import_attempt_count\n",
    "\n",
    "success_count, total_count = import_to_redcap(rci, rci_df)\n",
    "success_count, total_count, success_count == total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try importing data into an event which doesn't contain fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_bad = [\n",
    "    {'record_id': '1',\n",
    "     'redcap_event_name': 'baseline_arm_1',\n",
    "     'redcap_repeat_instrument': '',\n",
    "     'redcap_repeat_instance': '',\n",
    "     'exam_visit_date': '2017-08-01',\n",
    "     'exam_num_teeth': '6',\n",
    "     'exam_active_caries_count': 3,\n",
    "    },\n",
    "    {'record_id': '2',\n",
    "     'redcap_event_name': 'baseline_arm_1',\n",
    "     'redcap_repeat_instrument': '',\n",
    "     'redcap_repeat_instance': '',     \n",
    "     'exam_visit_date': '2017-08-02',\n",
    "     'exam_num_teeth': '7',\n",
    "     'exam_active_caries_count': 4,\n",
    "    },\n",
    "\n",
    "    {'record_id': '4',\n",
    "     'redcap_event_name': 'baseline_arm_1',\n",
    "     'redcap_repeat_instrument': '',\n",
    "     'redcap_repeat_instance': '',     \n",
    "     'exam_visit_date': '2017-08-04',\n",
    "     'exam_num_teeth': '8',\n",
    "     'exam_active_caries_count': 5,\n",
    "    },\n",
    "    {'record_id': '5',\n",
    "     'redcap_event_name': 'baseline_arm_1',\n",
    "     'redcap_repeat_instrument': '',\n",
    "     'redcap_repeat_instance': '',     \n",
    "     'exam_visit_date': '2017-08-03',\n",
    "     'exam_num_teeth': '8',\n",
    "     'exam_active_caries_count': 5,\n",
    "    },    \n",
    "]\n",
    "\n",
    "bad_df = pd.DataFrame(rc_bad)\n",
    "\n",
    "try:\n",
    "    success_count, total_count = import_to_redcap(rci, bad_df)\n",
    "    print(success_count, total_count, success_count == total_count)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, export the data to extract the arm info after randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_export = rce.export_records(rawOrLabel='raw')\n",
    "rc_export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a mapping of record ids to their respective arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_arm = dict(map(lambda x: (x['record_id'], x['rand_color']),  rc_export))\n",
    "\n",
    "# Use below if post-randomization data already exists in Redcap\n",
    "id_to_arm = dict(map(lambda x: (x['record_id'], x['rand_color']), \n",
    "                     list(filter(lambda d: d['redcap_event_name'] == 'baseline_arm_1' \n",
    "                                 and not d['redcap_repeat_instrument'], rc_export))))\n",
    "\n",
    "id_to_arm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Post-randomization test data\n",
    "- However, depending on the randomization schedule, it is not clear which arm to use without checking each ID in Redcap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_rand_import = [ \n",
    "    {'record_id': '1',\n",
    "     'redcap_event_name': 'baseline_arm_1',\n",
    "     'rand_date': '2017-08-01',\n",
    "    },\n",
    "    {'record_id': '2',\n",
    "     'redcap_event_name': 'baseline_arm_1',    \n",
    "     'rand_date': '2017-08-02',\n",
    "    },\n",
    "    {'record_id': '5',\n",
    "     'redcap_event_name': 'baseline_arm_1',    \n",
    "     'rand_date': '2017-08-03',\n",
    "    },   \n",
    "    {'record_id': '1',\n",
    "     'redcap_event_name': '6_month_arm_',      # Note events are incomplete\n",
    "     'exam_visit_date': '2018-02-01',\n",
    "     'exam_num_teeth': '11',\n",
    "    },\n",
    "    {'record_id': '2',\n",
    "     'redcap_event_name': '6_month_arm_',  \n",
    "     'exam_visit_date': '2018-02-02',\n",
    "     'exam_num_teeth': '25',  \n",
    "    },\n",
    "    {'record_id': '5',\n",
    "     'redcap_event_name': '6_month_arm_',   \n",
    "     'exam_visit_date': '2018-02-03',\n",
    "     'exam_num_teeth': '28', \n",
    "    },\n",
    "    {'record_id': '1',\n",
    "     'redcap_event_name': '6_month_arm_',\n",
    "     'redcap_repeat_instrument': 'phone_follow_up',\n",
    "     'redcap_repeat_instance': '1',\n",
    "     'pfu_contact_date': '2018-03-01', \n",
    "     'pfu_call_outcome': 1,\n",
    "     'pfu_ae_reported': '',\n",
    "     'pfu_ae_grade': '',\n",
    "     'pfu_ae_attribution': '',\n",
    "     'pfu_ae_serious': '',     \n",
    "    },\n",
    "    {'record_id': '1',\n",
    "     'redcap_event_name': '6_month_arm_',\n",
    "     'redcap_repeat_instrument': 'phone_follow_up',\n",
    "     'redcap_repeat_instance': '1',     \n",
    "     'pfu_contact_date': '2018-03-15',  \n",
    "     'pfu_call_outcome': 1,\n",
    "     'pfu_ae_reported': '',\n",
    "     'pfu_ae_grade': '',\n",
    "     'pfu_ae_attribution': '',\n",
    "     'pfu_ae_serious': '',      \n",
    "    },\n",
    "    {'record_id': '1',\n",
    "     'redcap_event_name': '6_month_arm_',\n",
    "     'redcap_repeat_instrument': 'phone_follow_up',\n",
    "     'redcap_repeat_instance': '1',     \n",
    "     'pfu_contact_date': '2018-03-30',\n",
    "     'pfu_call_outcome': 2,\n",
    "     'pfu_ae_reported': 1,\n",
    "     'pfu_ae_grade': 1,\n",
    "     'pfu_ae_attribution': 5,\n",
    "     'pfu_ae_serious': 0,\n",
    "    },\n",
    "    {'record_id': '2',\n",
    "     'redcap_event_name': '6_month_arm_',\n",
    "     'redcap_repeat_instrument': 'phone_follow_up',\n",
    "     'redcap_repeat_instance': '2',     \n",
    "     'pfu_contact_date': '2018-04-02',   \n",
    "     'pfu_call_outcome': 1,\n",
    "     'pfu_ae_reported': '',\n",
    "     'pfu_ae_grade': '',\n",
    "     'pfu_ae_attribution': '',\n",
    "     'pfu_ae_serious': '',      \n",
    "    },\n",
    "    {'record_id': '2',\n",
    "     'redcap_event_name': '6_month_arm_',\n",
    "     'redcap_repeat_instrument': 'phone_follow_up',\n",
    "     'redcap_repeat_instance': '2',     \n",
    "     'pfu_contact_date': '2018-04-03',  \n",
    "     'pfu_call_outcome': 1,\n",
    "     'pfu_ae_reported': '',\n",
    "     'pfu_ae_grade': '',\n",
    "     'pfu_ae_attribution': '',\n",
    "     'pfu_ae_serious': '',      \n",
    "    },   \n",
    "    {'record_id': '5',\n",
    "     'redcap_event_name': '6_month_arm_',\n",
    "     'redcap_repeat_instrument': 'phone_follow_up',\n",
    "     'redcap_repeat_instance': '1',     \n",
    "     'pfu_contact_date': '2018-05-02',    \n",
    "     'pfu_call_outcome': 2,\n",
    "     'pfu_ae_reported': 1,\n",
    "     'pfu_ae_grade': 3,\n",
    "     'pfu_ae_attribution': 1,\n",
    "     'pfu_ae_serious': 1,\n",
    "    },      \n",
    "    {'record_id': '1',\n",
    "     'redcap_event_name': '12_month_arm_',\n",
    "     'redcap_repeat_instrument': '',\n",
    "     'redcap_repeat_instance': '',   \n",
    "     'exam_visit_date': '2018-08-02',\n",
    "     'exam_num_teeth': '18',    \n",
    "    },\n",
    "]\n",
    "\n",
    "post_rand_import = [d for d in post_rand_import]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate the list and update the event name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_post_rand_import = []\n",
    "\n",
    "for d in post_rand_import:\n",
    "    d_new = {}\n",
    "    [d_new.update({k: v + id_to_arm[d['record_id']]}) \n",
    "                 if k == 'redcap_event_name' and v[-1] == '_' else d_new.update({k: v}) for k, v in d.items()]\n",
    "    new_post_rand_import.append(d_new)\n",
    "    \n",
    "new_post_rand_import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat above using a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_rand_df = pd.DataFrame(post_rand_import)\n",
    "post_rand_df.redcap_event_name = post_rand_df.apply(lambda row: row.redcap_event_name + id_to_arm[row.record_id] \n",
    "                                                    if row.redcap_event_name[-1] == '_' else row.redcap_event_name,\n",
    "                                                    axis=1)\n",
    "post_rand_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort by ID and event\n",
    "- To store sorted results, reassign result to DataFrame or use option inplace=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_rand_df.sort_values(by=['record_id', 'redcap_event_name', 'redcap_repeat_instance'])\n",
    "\n",
    "# Option 1:\n",
    "# post_rand_df = post_rand_df.sort_values(by=['record_id', 'redcap_event_name', 'redcap_repeat_instance'])\n",
    "\n",
    "# Option 2:\n",
    "# post_rand_df.sort_values(by=['record_id', 'redcap_event_name', 'redcap_repeat_instance'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Post-Randomization Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_count, total_count = import_to_redcap(rci, post_rand_df)\n",
    "success_count, total_count, success_count == total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check all the types of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_rand_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check type cell by cell\n",
    "- It is important to keep in mind what type you may be dealing with when applying operations to rows or columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_rand_df.applymap(type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you need to view or use data without NaNs\n",
    "- For a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_rand_df.redcap_repeat_instance.replace(np.NaN, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_rand_df.apply(lambda col: col.replace(np.NaN, ''))\n",
    "# post_rand_df.apply(lambda col: col.replace(np.NaN, '', inplace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Or, more succinctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_rand_df.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try computing the mean number of teeth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(post_rand_df.exam_num_teeth.mean())\n",
    "except TypeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try converting to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(post_rand_df.exam_num_teeth.apply(int))\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_rand_df.exam_num_teeth = post_rand_df.exam_num_teeth.apply(lambda x: int(x) if isinstance(x, str) else x)\n",
    "post_rand_df.exam_num_teeth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now compute the mean\n",
    "- Note above that ints are converted to floats due to column type containing NaNs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_rand_df.exam_num_teeth.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export a clean copy of all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_export = rce.export_records()\n",
    "new_df = pd.DataFrame(new_export)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To filter data by event and fields\n",
    "- For performance reasons, filtering is especially important once the project accrues data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rce.export_records(events=['baseline_arm_1'], fields=['record_id', 'rand_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data is exported from Redcap as str\n",
    "- So type conversion is typically an essential component of working with exported data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.applymap(type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the Data Dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = rce.export_data_dictionary()\n",
    "dd_df = pd.DataFrame(dd)\n",
    "dd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to search field names or labels for substring from the Data Dictionary\n",
    "- Case insensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_dd(df, search_str):\n",
    "    return df[df.apply(lambda row: True if search_str.lower() in row.field_label.lower() \n",
    "#                        or search_str.lower() in row.form_name.lower()\n",
    "                        or search_str.lower() in row.field_name.lower() else False, axis=1)]\n",
    "\n",
    "search_dd(dd_df, 'date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to show all fields associated with a particular form (from the Data Dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_form_fields(df, form_name):\n",
    "    return df[df.apply(lambda row: True if row.form_name == form_name else False, axis=1)]\n",
    "\n",
    "get_all_form_fields(dd_df, 'phone_follow_up')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to search column names for a substring\n",
    "- Useful for data exports from projects with a large number of variables\n",
    "- Case insensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_col(df, subs):\n",
    "    return list(filter(lambda x: subs.lower() in x.lower(), df.columns))\n",
    "\n",
    "find_col(post_rand_df, 'ex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Armed with the Data Dictionary, let's mark forms as complete in Redcap via the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the latest export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, reset the max number of DataFrame columns and rows displayed in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Every Redcap form has a hidden completion variable \n",
    "- Form name, separated by underscore, and appended with '_complete'\n",
    "- It is possible that a variable was named with the same suffix, so there is no guarantee that a field with this suffix is in fact the form completion variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_fields = find_col(new_df, '_complete')  # in this example, these are all form completion fields\n",
    "complete_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working assumptions \n",
    "- All forms we have worked with should have been marked complete\n",
    "- Except for randomization, where anyone not randomized is left as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(lambda x: x.split('_complete')[0], dd_df.form_name.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function to use for each row of the DataFrame\n",
    "def check_completion(roe, f):\n",
    "#     set_trace()\n",
    "    # First, validate the field name against the dictionary by seeing if the prefix is a form\n",
    "    if f.split('_complete')[0] in list(map(lambda x: x, dd_df.form_name.unique())):\n",
    "        if roe[f] == '0' and f != 'randomization_complete':\n",
    "            return '2' \n",
    "        elif roe[f] == '0' and f == 'randomization_complete' and roe['rand_date']:\n",
    "            return '2'\n",
    "        else:\n",
    "            return roe[f]\n",
    "    else:\n",
    "        roe[f]\n",
    "        \n",
    "# test_df = new_df.copy(deep=True)\n",
    "for field in complete_fields:\n",
    "    new_df[field] = new_df.apply(lambda row: check_completion(row, field), axis=1)\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_field_list = ['redcap_event_name', 'redcap_repeat_instrument', 'redcap_repeat_instance', 'record_id']\n",
    "complete_df = new_df[core_field_list + complete_fields].copy(deep=True)\n",
    "complete_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the completion fields and review Dashboard in Redcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_count, total_count = import_to_redcap(rci, complete_df)\n",
    "success_count, total_count, success_count == total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import a file\n",
    "- Display in notebook\n",
    "- Ref: https://stackoverflow.com/questions/32370281/how-to-include-image-or-picture-in-jupyter-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "img_url = 'https://image.shutterstock.com/z/stock-vector-cartoon-tooth-giving-thumb-up-602566124.jpg'\n",
    "display.Image(url=img_url, width=200, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store image to file\n",
    "- Ref: http://www.effbot.org/imagingbook/introduction.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "response = requests.get(img_url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "img_filename = 'happy_tooth.jpg'\n",
    "img.save(img_filename, 'JPEG')\n",
    "img.show()  # Opens an external application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a column containing the filename\n",
    "- Depending on your environment, you may want to use a full path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['exam_photo'] = new_df.exam_complete.apply(lambda x: img_filename if x == '2' else '')\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the files\n",
    "- Redcap has a delete file API endpoint, but it is not yet implemented in Redcapy\n",
    "- A Redcap variable is associated with a single file, so a different file will overwrite an existing file\n",
    "- Redcap should be able to accept any type of file, but only html and image files have been tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import redcap.redcapy\n",
    "\n",
    "def do_file(action):\n",
    "    \"\"\"\n",
    "        :param action: str, Values are import/delete\n",
    "    \"\"\"\n",
    "    valid_actions = ['import', 'delete']\n",
    "    \n",
    "    if action not in valid_actions:\n",
    "        raise ValueError('Invalid action argument passed.  Must be one of {}'.format(', '.join(valid_actions)))\n",
    "    \n",
    "    returned_list = []\n",
    "    \n",
    "    for i, row in new_df.iterrows():\n",
    "        if os.path.exists(row.exam_photo):\n",
    "            filename = row.exam_photo if action == 'import' else ''\n",
    "            returned = rci.import_file(event = row.redcap_event_name,\n",
    "                                       field = 'exam_photo', \n",
    "                                       filename = filename, \n",
    "                                       record_id = row.record_id,\n",
    "                                       repeat_instance = '',\n",
    "                                       action = action,\n",
    "                                      )\n",
    "            returned_list.append(returned)\n",
    "            \n",
    "    return returned_list\n",
    "    \n",
    "result = do_file('import')\n",
    "result, sum(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the files from Redcap that were just imported "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = do_file('delete')\n",
    "result, sum(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data Efficiently\n",
    "- For projects with large amounts of data (fields and/or participants), economize use of the export API\n",
    " - Implement local caching of data\n",
    " - Limit export to select fields or events\n",
    "  - Redcapy will have a record id option in a future update\n",
    "   - This will allow you to cache an object containing record_ids to exclude from data exports, or write to a flat file\n",
    "    - One implementation idea: \n",
    "     - As IDs meet a permanent condition, write record_id to exclusion object\n",
    "     - When launching code, first download a full list of record_ids.\n",
    "     - Open and check exclusion list against the full list of ids.\n",
    "     - Export a difference of all IDs and exlcusions.\n",
    "    - The export efficiency may be nominal at first, but can become substantial as the project accrues more participants.\n",
    "- Start a notebook cell with %%time command to evaluate how long it takes to execute the cell\n",
    " - A full list of available magic commands can be viewed by executing %magic in a cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?%time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caching\n",
    "- Jupyter notebooks can use the %store magic command\n",
    " - Ref: https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/\n",
    " - %store also allows you to access stored objects from any notebook\n",
    " - Storage is persistent on disk\n",
    " - Stored objects are located (your results may vary) in:\n",
    "   - ~/.ipython/profile_default/db/autorestore\n",
    " - Object names should be unique, as an identically named object from one notebook can overwrite one from another\n",
    "- Python programs can use pickle\n",
    " -  Ref: https://www.thoughtco.com/using-pickle-to-save-objects-2813661\n",
    "\n",
    "\n",
    "#### %store Magic command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cached_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_cached_data:\n",
    "    caps_data_export = rce.export_records(rawOrLabel='raw')\n",
    "    caps_dd_export = rce.export_data_dictionary()\n",
    "\n",
    "    # Store data for future use to avoid API calls\n",
    "    %store caps_data_export\n",
    "    %store caps_dd_export\n",
    "else:  # restore prior data\n",
    "    %store -r caps_data_export \n",
    "    %store -r caps_dd_export "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limiting export by field or event\n",
    "- Specify events by their raw version \n",
    " - e.g., 'baseline_arm_1', not 'Baseline (Arm 1: Baseline)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data = rce.export_records(events='baseline_arm_1')\n",
    "baseline_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "baseline_data = rce.export_records(events='baseline_arm_1')\n",
    "# baseline_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter further by field name\n",
    "- Use a comma separated string to extract multiple events or fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_names = rce.export_records(events='baseline_arm_1', fields='part_first_name, part_last_name')\n",
    "baseline_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the number of teeth from exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_baseline_teeth = rce.export_records(events='6_month_arm_2, 6_month_arm_3, 12_month_arm_2, 12_month_arm_3', \n",
    "                                         fields='exam_num_teeth')\n",
    "post_baseline_teeth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now add record_id to the list of fields\n",
    "- Note the change in data returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_baseline_teeth = rce.export_records(events='6_month_arm_2, 6_month_arm_3, 12_month_arm_2, 12_month_arm_3', \n",
    "                                         fields='record_id, exam_num_teeth')\n",
    "post_baseline_teeth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using labels and raw data\n",
    "- Python does not natively offer the same convenience as SAS for handling labeled data, as with SAS formats\n",
    "- However we can improvise by using a mix of raw and labeled data exports\n",
    "- During a project in production, consider the likelihood of whether your raw or labeled values may change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_export = rce.export_records(rawOrLabel='raw')\n",
    "label_export = rce.export_records(rawOrLabel='label')\n",
    "\n",
    "raw_df = pd.DataFrame.from_records(raw_export)\n",
    "label_df = pd.DataFrame.from_records(label_export)\n",
    "\n",
    "raw_df.shape, label_df.shape, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View raw equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A trick is to alter the variable names of the labeled variable names\n",
    "- For example, you could perform calculations using the raw values and display the labeled values of an ordinal variable\n",
    "- Combine both raw and labeled DataFrames into a single DataFrame, appending a '_label' suffix to the column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_dfs(dfraw, dflabel):\n",
    "    rc_keys = ['record_id', 'redcap_repeat_instance']  # These are identical in both DataFrames\n",
    "    dflabel2 = dflabel.copy(deep=True).rename(columns={col: '{}_label'.format(col) \n",
    "                                                       for col in dflabel.columns \n",
    "                                                       if col not in rc_keys})\n",
    "    df = pd.concat([dfraw, dflabel2], levels=rc_keys, axis=1)\n",
    "    \n",
    "    # Remove columns with dup col names, Ref: https://stackoverflow.com/a/16939512\n",
    "    df = df.T.groupby(level=0).first().T  \n",
    "    \n",
    "    return df\n",
    "   \n",
    "combined_df = join_dfs(raw_df, label_df)\n",
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = combined_df.pfu_ae_grade.apply(lambda x: int(x) if x.isdigit() else np.NaN)\n",
    "grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of IDs and Grades where the Grade > Mean Grade\n",
    "#### First create a filter for the DataFrame to extract rows corresponding to mask rows == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = grades > grades.mean()\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, apply the mask to the DataFrame, and specify a list of columns of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[mask][['record_id', 'pfu_ae_grade_label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple filters can be more easily written as a one-liner, but readability improves as a separate line for more complex filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[grades > grades.mean()][['record_id', 'pfu_ae_grade_label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typically, you may work directly with DataFrame columns to use as a filter\n",
    "- For a series that requires a transformation like pfu_ae_grade, you might assign the transformed series to a DataFrame as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['pfu_ae_grade_num'] = combined_df.pfu_ae_grade.apply(lambda x: int(x) if x.isdigit() \n",
    "                                                                else np.NaN)\n",
    "combined_df[combined_df.pfu_ae_grade_num > combined_df.pfu_ae_grade_num.mean()][['record_id', 'pfu_ae_grade_label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you have a series of variables requiring a similar computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_above_mean(df, field):\n",
    "    num_name = field + '_num'\n",
    "    df[num_name] = df[field].apply(lambda x: int(x) if x.isdigit() else np.NaN)\n",
    "\n",
    "    return df[df[num_name] > df[num_name].mean()][['record_id', field + '_label']]\n",
    "    \n",
    "compute_above_mean(combined_df, 'pfu_ae_grade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_above_mean(combined_df, 'pfu_ae_serious')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with import overwrite behavior\n",
    "- Null data elements should not overwrite extant data in Redcap by default\n",
    "- In the Redcapy import_data method, the parameter overwriteBehavior == 'normal' by default\n",
    " - Setting overwriteBehavior='overwrite' will overwrite Redcap data with blanks\n",
    " - In a worst case scenario, if you begin with a DataFrame scaffold of all fields, populate some fields of interest, and import with overwrite set to 'overwrite' it will erase all other fields corresponding to those IDs and events.\n",
    "- Normally, you will want to use the default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rci.import_records(data_to_upload=data_to_import, overwriteBehavior='normal')  # default\n",
    "# rci.import_records(data_to_upload=data_to_import, overwriteBehavior='overwrite') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store this DataFrame for use in the next notebook\n",
    "- Creata a name that is unique across all notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps_combined_df = combined_df\n",
    "%store caps_combined_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
